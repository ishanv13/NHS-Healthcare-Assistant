{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#NHS Healthcare Assistant"
      ],
      "metadata": {
        "id": "E0RNgP34BOK0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Load Packages\n"
      ],
      "metadata": {
        "id": "bQl5TtZqC0p4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TvQRV_-GWoP0"
      },
      "outputs": [],
      "source": [
        "!pip install langchain pypdf sentence-transformers ctransformers chromadb -q"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Data Loading & Processing\n",
        "We will create a directory (`docs`) where we will load all the documents."
      ],
      "metadata": {
        "id": "-tflHUO7C_zE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir docs"
      ],
      "metadata": {
        "id": "KdtZ9MWvDCK7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "64651db1-2da7-47db-d5e6-5125d753851b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘docs’: File exists\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now upload all the files to this directory"
      ],
      "metadata": {
        "id": "gfceWWmMDLN_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wget -q"
      ],
      "metadata": {
        "id": "NquUCZNmDK7w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The below code allows the user to import data from a github reporsitory or google drive link, which is optional."
      ],
      "metadata": {
        "id": "tLMcU6cqjHPi"
      }
    },
    {
      "source": [
        "import wget\n",
        "import os\n",
        "import requests\n",
        "\n",
        "def get_github_files(repo_owner, repo_name, directory_path):\n",
        "  \"\"\"\n",
        "  Fetches a list of PDF files from a GitHub repository directory.\n",
        "\n",
        "  Args:\n",
        "      repo_owner (str): The owner of the GitHub repository.\n",
        "      repo_name (str): The name of the GitHub repository.\n",
        "      directory_path (str): The path to the directory within the repository.\n",
        "\n",
        "  Returns:\n",
        "      list: A list of file URLs for the PDF files in the directory.\n",
        "  \"\"\"\n",
        "  api_url = f\"https://api.github.com/repos/{repo_owner}/{repo_name}/contents/{directory_path}\"\n",
        "  headers = {\"Accept\": \"application/vnd.github+json\"}  # For the latest API version\n",
        "  response = requests.get(api_url, headers=headers)\n",
        "  response.raise_for_status()  # Raise an exception for bad status codes\n",
        "\n",
        "  pdf_files = []\n",
        "  for file_data in response.json():\n",
        "      if file_data[\"type\"] == \"file\" and file_data[\"name\"].endswith(\".pdf\"):\n",
        "          # Use file_data['path'] to construct the correct download URL\n",
        "          # to handle spaces and special characters in file names.\n",
        "          download_url = f\"https://raw.githubusercontent.com/{repo_owner}/{repo_name}/main/{file_data['path']}\"\n",
        "          pdf_files.append(download_url)\n",
        "  return pdf_files\n",
        "\n",
        "# --- Usage ---\n",
        "repo_owner = \"ishanv13\"\n",
        "repo_name = \"NHS-Healthcare-Assistant\"\n",
        "directory_path = \"Patient2\"\n",
        "\n",
        "pdf_urls = get_github_files(repo_owner, repo_name, directory_path)\n",
        "\n",
        "# Create the 'docs' directory if it doesn't exist\n",
        "os.makedirs(\"docs\", exist_ok=True)\n",
        "\n",
        "# Download the PDF files\n",
        "for url in pdf_urls:\n",
        "    filename = os.path.basename(url)\n",
        "    wget.download(url, out=os.path.join(\"docs\", filename))\n",
        "    print(f\"Downloaded: {filename}\")"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ntVVsl-A7-UT",
        "outputId": "039fd6a8-c6fa-4549-c9a8-e49010173bbb"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloaded: JD Current Symptoms 2025.pdf\n",
            "Downloaded: JD Medical History 2020.pdf\n",
            "Downloaded: JD Medical History 2021.pdf\n",
            "Downloaded: JD Medical History 2022.pdf\n",
            "Downloaded: JD Medical History 2023.pdf\n",
            "Downloaded: JD Medical History 2024.pdf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pysqlite3"
      ],
      "metadata": {
        "id": "k7qUo5AaD08A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "688741d2-dd39-4227-b398-0f59e6fc48ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pysqlite3 in /usr/local/lib/python3.11/dist-packages (0.5.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The user can upload the initial files or report here."
      ],
      "metadata": {
        "id": "zJzscJ4hjQWa"
      }
    },
    {
      "source": [
        "'''import sqlite3\n",
        "import os\n",
        "\n",
        "def upload_pdf_to_db(pdf_path, db_name=\"my_database.db\"):\n",
        "  \"\"\"\n",
        "  Uploads PDF content to a SQLite database, storing it in the 'docs' folder.\n",
        "\n",
        "  Args:\n",
        "      pdf_path (str): The path to the PDF file.\n",
        "      db_name (str, optional): The name of the database file. Defaults to \"my_database.db\".\n",
        "  \"\"\"\n",
        "  with open(pdf_path, \"rb\") as f:\n",
        "      pdf_data = f.read()\n",
        "\n",
        "  conn = sqlite3.connect(db_name)\n",
        "  cursor = conn.cursor()\n",
        "\n",
        "  # Create the 'docs' table if it doesn't exist\n",
        "  cursor.execute(\"\"\"\n",
        "      CREATE TABLE IF NOT EXISTS docs (\n",
        "          id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
        "          filename TEXT,\n",
        "          data BLOB\n",
        "      )\n",
        "  \"\"\")\n",
        "\n",
        "  # Insert the PDF data into the 'docs' table\n",
        "  cursor.execute(\"INSERT INTO docs (filename, data) VALUES (?, ?)\", (os.path.basename(pdf_path), pdf_data))\n",
        "\n",
        "  conn.commit()\n",
        "  conn.close()\n",
        "\n",
        "# Example usage within Colab (replace with your file upload method)\n",
        "from google.colab import files\n",
        "\n",
        "# Create the directory if it doesn't exist\n",
        "os.makedirs(\"/content/docs\", exist_ok=True)\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for filename, data in uploaded.items():\n",
        "    # Save the file to /content/docs\n",
        "    file_path = os.path.join(\"/content/docs\", filename)\n",
        "    with open(file_path, \"wb\") as f:\n",
        "        f.write(data)\n",
        "    upload_pdf_to_db(file_path)  # Use the full path for the database\n",
        "\n",
        "print(\"PDF files uploaded to the database (docs table).\")'''"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120
        },
        "id": "_DBmHMclDujg",
        "outputId": "2bcf2f53-391a-4d99-e0b9-520c4634d5e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'import sqlite3\\nimport os\\n\\ndef upload_pdf_to_db(pdf_path, db_name=\"my_database.db\"):\\n  \"\"\"\\n  Uploads PDF content to a SQLite database, storing it in the \\'docs\\' folder.\\n\\n  Args:\\n      pdf_path (str): The path to the PDF file.\\n      db_name (str, optional): The name of the database file. Defaults to \"my_database.db\".\\n  \"\"\"\\n  with open(pdf_path, \"rb\") as f:\\n      pdf_data = f.read()\\n\\n  conn = sqlite3.connect(db_name)\\n  cursor = conn.cursor()\\n\\n  # Create the \\'docs\\' table if it doesn\\'t exist\\n  cursor.execute(\"\"\"\\n      CREATE TABLE IF NOT EXISTS docs (\\n          id INTEGER PRIMARY KEY AUTOINCREMENT,\\n          filename TEXT,\\n          data BLOB\\n      )\\n  \"\"\")\\n\\n  # Insert the PDF data into the \\'docs\\' table\\n  cursor.execute(\"INSERT INTO docs (filename, data) VALUES (?, ?)\", (os.path.basename(pdf_path), pdf_data))\\n\\n  conn.commit()\\n  conn.close()\\n\\n# Example usage within Colab (replace with your file upload method)\\nfrom google.colab import files\\n\\n# Create the directory if it doesn\\'t exist\\nos.makedirs(\"/content/docs\", exist_ok=True)\\n\\nuploaded = files.upload()\\n\\nfor filename, data in uploaded.items():\\n    # Save the file to /content/docs\\n    file_path = os.path.join(\"/content/docs\", filename)\\n    with open(file_path, \"wb\") as f:\\n        f.write(data)\\n    upload_pdf_to_db(file_path)  # Use the full path for the database\\n\\nprint(\"PDF files uploaded to the database (docs table).\")'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "source": [
        "!pip install langchain-community"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "6n6F2C8WDoQa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "122a9214-4bff-4f2b-e0ce-6dad82cd079e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain-community in /usr/local/lib/python3.11/dist-packages (0.3.23)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.56 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.56)\n",
            "Requirement already satisfied: langchain<1.0.0,>=0.3.24 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.24)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.0.40)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (6.0.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (3.11.15)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (9.1.2)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.6.7)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.9.1)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.39)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.4.0)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.20.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.26.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.24->langchain-community) (0.3.8)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.24->langchain-community) (2.11.4)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.56->langchain-community) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.56->langchain-community) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.56->langchain-community) (4.13.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (3.10.18)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (0.23.0)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (1.1.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (0.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (2025.4.26)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.2.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.56->langchain-community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.24->langchain-community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.24->langchain-community) (2.33.2)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.1.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (1.3.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter"
      ],
      "metadata": {
        "id": "9-t1QsfMGDfA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Read all the files in the directory"
      ],
      "metadata": {
        "id": "u5QiiORTGNZ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "# Assuming PDFs are in a 'docs' folder\n",
        "pdf_folder_path = 'docs/'\n",
        "if not os.path.exists(pdf_folder_path):\n",
        "    print(f\"Error: '{pdf_folder_path}' not found. Please upload your PDFs there.\")\n",
        "else:\n",
        "    loaders = [PyPDFLoader(os.path.join(pdf_folder_path, fn)) for fn in os.listdir(pdf_folder_path) if fn.endswith('.pdf')]\n",
        "    print(f\"Found {len(loaders)} PDF documents.\")\n",
        "    docs = []\n",
        "    for loader in loaders:\n",
        "        docs.extend(loader.load())\n",
        "    print(f\"Loaded {len(docs)} pages total.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_vZj5GWKGJbW",
        "outputId": "2c5380e9-31a5-452d-a0e5-2773d70b45a9"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 8 PDF documents.\n",
            "Loaded 13 pages total.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Split the documents into chunks that are overlapping.\n"
      ],
      "metadata": {
        "id": "955estTfH24O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=200, chunk_overlap=25)\n",
        "splits = text_splitter.split_documents(docs)\n",
        "print(f\"Split into {len(splits)} chunks.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QyiqTLm3HyD2",
        "outputId": "23ae8186-7816-4755-b7be-5f2e1e4470f9"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Split into 90 chunks.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i, split in enumerate(splits):\n",
        "    print(f\"Chunk {i + 1}:\\n{split.page_content}\\n\")"
      ],
      "metadata": {
        "id": "cpAM_oL6H0YM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "95f31dd6-682a-4e22-ce35-1472f1dc6aaf"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chunk 1:\n",
            "Synthetic Medical History - John Doe \n",
            "John Doe - Full Medical History (2020-2025) \n",
            "Extended Synthetic Medical History for John Doe (Age 27, AB+) \n",
            "Primary Profile:\n",
            "\n",
            "Chunk 2:\n",
            "Primary Profile: \n",
            "- Pre-existing Conditions: Asthma (since childhood), IBS (diagnosed 2021), Allergic Rhinitis\n",
            "\n",
            "Chunk 3:\n",
            "- Medications: Albuterol (PRN), Cetirizine, Dicyclomine (as needed), Vitamin D3 (since 2024) \n",
            "- Lifestyle: Office worker, sedentary with intermittent exercise; non-smoker; moderate alcohol use\n",
            "\n",
            "Chunk 4:\n",
            "- Family History: Mother has Type 2 Diabetes, father has hypertension \n",
            "Urgent Care Visit – April 2025 \n",
            "- Complaint: Fever\n",
            "\n",
            "Chunk 5:\n",
            "- Complaint: Fever \n",
            "(101.8°F), malaise, itchy rash with vesicles starting on trunk, spreading to face and li\n",
            "mbs over 24 hours.\n",
            "\n",
            "Chunk 6:\n",
            "mbs over 24 hours. \n",
            "- History: No prior varicella infection or vaccination confirmed; recent contact with co\n",
            "worker’s child who had “a rash.”\n",
            "\n",
            "Chunk 7:\n",
            "- Exam Findings: Multiple small vesicular lesions on erythematous bases, some crusti\n",
            "ng noted; no secondary bacterial infection. \n",
            "- Diagnosis: Varicella (chickenpox) – clinically confirmed.\n",
            "\n",
            "Chunk 8:\n",
            "- Plan: Symptomatic treatment \n",
            "– acetaminophen for fever, calamine lotion and oral antihistamines for itching. \n",
            "- Precautions: Advised isolation until lesions crusted over\n",
            "\n",
            "Chunk 9:\n",
            "(~7 days); return to work clearance to be re-evaluated by PCP. \n",
            "- Follow-up: PCP appointment recommended in 10–\n",
            "14 days to ensure resolution and monitor for complications (e.g., pneumonia).\n",
            "\n",
            "Chunk 10:\n",
            "Primary Care Follow-up Visit – April 2025 (2 weeks post-diagnosis) \n",
            "- S: Patient reports improvement in energy and resolution of fever. Rash has mostly cru\n",
            "\n",
            "Chunk 11:\n",
            "sted, some residual scabbing. No breathing issues or new symptoms. \n",
            "- O: Temp 98.4°F, HR 72, BP \n",
            "118/76. Skin: healing lesions with no signs of secondary infection. Lungs clear on aus\n",
            "cultation.\n",
            "\n",
            "Chunk 12:\n",
            "cultation. \n",
            "- A: Recovering varicella infection, no complications noted. \n",
            "- P: Cleared to return to work. Advised moisturizers for skin healing. No further follow\n",
            "-up needed unless symptoms recur.\n",
            "\n",
            "Chunk 13:\n",
            "Synthetic Medical History - John Doe \n",
            "John Doe - Full Medical History (2020-2025) \n",
            "Extended Synthetic Medical History for John Doe (Age 27, AB+) \n",
            "Primary Profile:\n",
            "\n",
            "Chunk 14:\n",
            "Primary Profile: \n",
            "- Pre-existing Conditions: Asthma (since childhood), IBS (diagnosed 2021), Allergic Rhinitis\n",
            "\n",
            "Chunk 15:\n",
            "- Medications: Albuterol (PRN), Cetirizine, Dicyclomine (as needed), Vitamin D3 (since 2024) \n",
            "- Lifestyle: Office worker, sedentary with intermittent exercise; non-smoker; moderate alcohol use\n",
            "\n",
            "Chunk 16:\n",
            "- Family History: Mother has Type 2 Diabetes, father has hypertension \n",
            " \n",
            "MEDICAL HISTORY \n",
            "Gastroenterology Consultation - Jan 2021\n",
            "\n",
            "Chunk 17:\n",
            "- Complaint: Bloating, alternating diarrhea/constipation, stress-related flares \n",
            "- Diagnosis: Irritable Bowel Syndrome (IBS-D subtype)\n",
            "\n",
            "Chunk 18:\n",
            "- Plan: Low FODMAP diet trial, PRN Dicyclomine, referral to dietitian \n",
            " \n",
            "Routine Blood Test - May 2021 \n",
            "- Findings: Hb: 14.5 g/dL, WBC: 6.8 x10/L, Ferritin: 46 ng/mL, CRP: 1.2 mg/L\n",
            "\n",
            "Chunk 19:\n",
            "- Assessment: Normal \n",
            " \n",
            "Dietitian Report - June 2021 \n",
            "- Summary: IBS managed better with diet adherence; advised probiotic trial \n",
            "- Patient Feedback: Reduced bloating, fewer flares\n",
            "\n",
            "Chunk 20:\n",
            "Emergency Visit - Oct 2021  \n",
            "- Complaint: Acute wheezing + cough during a hike \n",
            "- Intervention: Nebulized albuterol, observed for 1 hour \n",
            "- Diagnosis: Asthma exacerbation\n",
            "\n",
            "Chunk 21:\n",
            "- Plan: Resume regular peak flow tracking, follow-up with PCP \n",
            "Routine Blood Test – May 2021 \n",
            "Reason: Baseline evaluation during IBS workup \n",
            "Test Result Reference Range\n",
            "\n",
            "Chunk 22:\n",
            "Hemoglobin (Hb) 14.5 g/dL 13.5–17.5 g/dL \n",
            "White Blood Cell Count 6.8 x10/L 4.0–11.0 x10/L \n",
            "Ferritin 46 ng/mL 30–300 ng/mL \n",
            "C-Reactive Protein (CRP) 1.2 mg/L <3.0 mg/L\n",
            "\n",
            "Chunk 23:\n",
            "Synthetic Medical History - John Doe \n",
            "John Doe - Full Medical History (2020-2025) \n",
            "Extended Synthetic Medical History for John Doe (Age 27, AB+) \n",
            "Primary Profile:\n",
            "\n",
            "Chunk 24:\n",
            "Primary Profile: \n",
            "- Pre-existing Conditions: Asthma (since childhood), IBS (diagnosed 2021), Allergic Rhinitis\n",
            "\n",
            "Chunk 25:\n",
            "- Medications: Albuterol (PRN), Cetirizine, Dicyclomine (as needed), Vitamin D3 (since 2024) \n",
            "- Lifestyle: Office worker, sedentary with intermittent exercise; non-smoker; moderate alcohol use\n",
            "\n",
            "Chunk 26:\n",
            "- Family History: Mother has Type 2 Diabetes, father has hypertension \n",
            " \n",
            "MEDICAL HISTORY \n",
            "Primary Care Visit - Feb 2020 \n",
            "- Complaint: Shortness of breath during workouts\n",
            "\n",
            "Chunk 27:\n",
            "- Note: Asthma symptoms increasing with winter; advised inhaler use pre-exercise. No signs of \n",
            "infection or wheeze on \n",
            "auscultation. \n",
            "- Plan: Refill albuterol, start tracking peak flow at home\n",
            "\n",
            "Chunk 28:\n",
            "Allergy Consultation - June 2020 \n",
            "- Referral Letter Summary: Persistent nasal congestion, itchy eyes \n",
            "- Skin Prick Testing: Positive for pollen, dust mites \n",
            "- Diagnosis: Allergic Rhinitis\n",
            "\n",
            "Chunk 29:\n",
            "- Plan: Begin daily antihistamine, advised HEPA filters at home\n",
            "\n",
            "Chunk 30:\n",
            "Synthetic Medical History - John Doe\n",
            "John Doe - Full Medical History (2020-2025)\n",
            " Extended Synthetic Medical History for John Doe (Age 27, AB+)\n",
            "Primary Profile:\n",
            "\n",
            "Chunk 31:\n",
            "Primary Profile:\n",
            "- Pre-existing Conditions: Asthma (since childhood), IBS (diagnosed 2021), Allergic Rhinitis\n",
            "\n",
            "Chunk 32:\n",
            "- Medications: Albuterol (PRN), Cetirizine, Dicyclomine (as needed), Vitamin D3 (since 2024)\n",
            "- Lifestyle: Office worker, sedentary with intermittent exercise; non-smoker; moderate alcohol use\n",
            "\n",
            "Chunk 33:\n",
            "- Family History: Mother has Type 2 Diabetes, father has hypertension\n",
            "---\n",
            "MEDICAL HISTORY: 2020-2025\n",
            "Primary Care Visit - Feb 2020\n",
            "- Complaint: Shortness of breath during workouts\n",
            "\n",
            "Chunk 34:\n",
            "- Note: Asthma symptoms increasing with winter; advised inhaler use pre-exercise. No signs of infection or wheeze on\n",
            "auscultation.\n",
            "- Plan: Refill albuterol, start tracking peak flow at home\n",
            "\n",
            "Chunk 35:\n",
            "Allergy Consultation - June 2020\n",
            "- Referral Letter Summary: Persistent nasal congestion, itchy eyes\n",
            "- Skin Prick Testing: Positive for pollen, dust mites\n",
            "- Diagnosis: Allergic Rhinitis\n",
            "\n",
            "Chunk 36:\n",
            "- Plan: Begin daily antihistamine, advised HEPA filters at home\n",
            "Gastroenterology Consultation - Jan 2021\n",
            "- Complaint: Bloating, alternating diarrhea/constipation, stress-related flares\n",
            "\n",
            "Chunk 37:\n",
            "- Diagnosis: Irritable Bowel Syndrome (IBS-D subtype)\n",
            "- Plan: Low FODMAP diet trial, PRN Dicyclomine, referral to dietitian\n",
            "Routine Blood Test - May 2021\n",
            "\n",
            "Chunk 38:\n",
            "- Findings: Hb: 14.5 g/dL, WBC: 6.8 x10/L, Ferritin: 46 ng/mL, CRP: 1.2 mg/L\n",
            "- Assessment: Normal\n",
            "Dietitian Report - June 2021\n",
            "\n",
            "Chunk 39:\n",
            "- Summary: IBS managed better with diet adherence; advised probiotic trial\n",
            "- Patient Feedback: Reduced bloating, fewer flares\n",
            "Emergency Visit - Oct 2021\n",
            "\n",
            "Chunk 40:\n",
            "Synthetic Medical History - John Doe\n",
            "- Complaint: Acute wheezing + cough during a hike\n",
            "- Intervention: Nebulized albuterol, observed for 1 hour\n",
            "- Diagnosis: Asthma exacerbation\n",
            "\n",
            "Chunk 41:\n",
            "- Plan: Resume regular peak flow tracking, follow-up with PCP\n",
            "Annual Physical - Jan 2022\n",
            "- BMI: 22.8, BP: 112/74, Labs normal\n",
            "- Assessment: Healthy, encouraged more consistent exercise\n",
            "\n",
            "Chunk 42:\n",
            "Pulmonary Function Test - July 2022\n",
            "- FEV1/FVC: Mild obstruction, reversible with bronchodilator\n",
            "- Diagnosis: Controlled asthma\n",
            "- Plan: Maintain current meds\n",
            "Psychiatry Referral - Nov 2022\n",
            "\n",
            "Chunk 43:\n",
            "- Note: Fatigue, stress-related GI issues, mild anxiety\n",
            "- Evaluation: Diagnosed with mild generalized anxiety\n",
            "- Plan: CBT recommended, no meds\n",
            "Eye Exam - April 2023\n",
            "\n",
            "Chunk 44:\n",
            "Eye Exam - April 2023\n",
            "- Complaint: Blurry vision after long screen time\n",
            "- Diagnosis: Digital eye strain\n",
            "- Plan: Blue-light filters, 20/20/20 rule\n",
            "Comprehensive Metabolic Panel - Sept 2023\n",
            "\n",
            "Chunk 45:\n",
            "- All values normal\n",
            "Allergy Panel - Oct 2023\n",
            "- Positive: Pollen, dust mites, cat dander\n",
            "- Plan: Continue Cetirizine, immunotherapy discussed\n",
            "Consultation Note - Mar 2024\n",
            "\n",
            "Chunk 46:\n",
            "- Complaint: Chronic fatigue, brain fog\n",
            "- Note: Diet and sleep suboptimal\n",
            "- Plan: Blood tests ordered\n",
            "Blood Test - Mar 2024\n",
            "- Findings: Vitamin D: 21 ng/mL, B12: 308 pg/mL, Ferritin: 34 ng/mL\n",
            "\n",
            "Chunk 47:\n",
            "- Plan: Start Vit D3, monitor fatigue\n",
            "Annual Physical - July 2024\n",
            "\n",
            "Chunk 48:\n",
            "Synthetic Medical History - John Doe\n",
            "- Vitals and urinalysis: Normal\n",
            "- Assessment: Fit for age, fatigue persists\n",
            "Consultation Note - Mar 2025\n",
            "- Complaint: Fatigue, unintentional 4 kg weight loss\n",
            "\n",
            "Chunk 49:\n",
            "- Exam: Pale conjunctiva noted\n",
            "- Plan: Blood tests, hematology referral\n",
            "Blood Test - Mar 2025\n",
            "- Findings: Hb: 11.9 g/dL, WBC: 4.0 x10/L, ESR: 28 mm/hr, CRP: 5.8 mg/L\n",
            "\n",
            "Chunk 50:\n",
            "- Assessment: Suspicion of chronic inflammation or hematologic issue\n",
            "Hematology Referral - May 2025\n",
            "- Autoimmune/Thyroid/Chest X-ray: Normal\n",
            "- Note: Bone marrow biopsy considered if anemia progresses\n",
            "\n",
            "Chunk 51:\n",
            "Current Differential:\n",
            "- Iron deficiency anemia with unclear etiology\n",
            "- Chronic inflammation vs. early autoimmune or hematologic disorder\n",
            "---\n",
            " Simulated Doctor-Patient SOAP Note (Feb 2025)\n",
            "\n",
            "Chunk 52:\n",
            "S: Patient reports feeling fatigued over past 3 months, with recent unintentional weight loss (~4 kg), occasional night\n",
            "sweats. Denies fever or recent travel.\n",
            "\n",
            "Chunk 53:\n",
            "O: BP 116/76, HR 74, Temp 98.1F, mild pallor, no lymphadenopathy, no hepatosplenomegaly.\n",
            "A: Likely anemia of chronic disease; weight loss concerning. Labs indicate elevated inflammatory markers.\n",
            "\n",
            "Chunk 54:\n",
            "P: Ordered repeat CBC, ESR/CRP, autoimmune screen, chest X-ray. Referral to hematology.\n",
            " Primary Care Follow-up Call Summary (April 2025)\n",
            "\n",
            "Chunk 55:\n",
            "Doctor: \"Hi John, I wanted to update you on the blood tests. Your inflammatory markers are still raised, and your\n",
            "\n",
            "Chunk 56:\n",
            "hemoglobin remains low. The hematologist agrees we should proceed with more testing if things don't improve next\n",
            "month.\"\n",
            "Patient: \"Okay. I still feel tired, but I'm managing.\"\n",
            "\n",
            "Chunk 57:\n",
            "Doctor: \"Continue your supplements and rest. We'll follow up again after your next lab.\"\n",
            "\n",
            "Chunk 58:\n",
            "DETAILED LAB REPORTS FOR JOHN DOE\n",
            "Routine Blood Test – May 2021\n",
            "Reason: Baseline evaluation during IBS workup\n",
            "Test\n",
            "Result\n",
            "Reference Range\n",
            "Hemoglobin (Hb)\n",
            "14.5 g/dL\n",
            "13.5–17.5 g/dL\n",
            "\n",
            "Chunk 59:\n",
            "14.5 g/dL\n",
            "13.5–17.5 g/dL\n",
            "White Blood Cell Count\n",
            "6.8 x10■/L\n",
            "4.0–11.0 x10■/L\n",
            "Ferritin\n",
            "46 ng/mL\n",
            "30–300 ng/mL\n",
            "C-Reactive Protein (CRP)\n",
            "1.2 mg/L\n",
            "<3.0 mg/L\n",
            "Comprehensive Metabolic Panel – Sept 2023\n",
            "\n",
            "Chunk 60:\n",
            "Reason: Annual screening\n",
            "Test\n",
            "Result\n",
            "Reference Range\n",
            "Glucose (fasting)\n",
            "89 mg/dL\n",
            "70–99 mg/dL\n",
            "BUN\n",
            "14 mg/dL\n",
            "7–20 mg/dL\n",
            "Creatinine\n",
            "0.91 mg/dL\n",
            "0.6–1.3 mg/dL\n",
            "Sodium\n",
            "139 mmol/L\n",
            "135–145 mmol/L\n",
            "Potassium\n",
            "\n",
            "Chunk 61:\n",
            "135–145 mmol/L\n",
            "Potassium\n",
            "4.3 mmol/L\n",
            "3.5–5.1 mmol/L\n",
            "ALT\n",
            "19 U/L\n",
            "7–56 U/L\n",
            "AST\n",
            "17 U/L\n",
            "10–40 U/L\n",
            "Blood Test – March 2024\n",
            "Reason: Evaluation for fatigue and brain fog\n",
            "Test\n",
            "Result\n",
            "Reference Range\n",
            "\n",
            "Chunk 62:\n",
            "Result\n",
            "Reference Range\n",
            "Vitamin D (25-OH)\n",
            "21 ng/mL\n",
            "30–100 ng/mL\n",
            "Vitamin B12\n",
            "308 pg/mL\n",
            "200–900 pg/mL\n",
            "Ferritin\n",
            "34 ng/mL\n",
            "30–300 ng/mL\n",
            "Blood Test – March 2025\n",
            "Reason: Persistent fatigue and weight loss\n",
            "\n",
            "Chunk 63:\n",
            "Test\n",
            "Result\n",
            "Reference Range\n",
            "Hemoglobin (Hb)\n",
            "11.9 g/dL\n",
            "13.5–17.5 g/dL\n",
            "White Blood Cell Count\n",
            "4.0 x10■/L\n",
            "4.0–11.0 x10■/L\n",
            "ESR\n",
            "28 mm/hr\n",
            "0–20 mm/hr\n",
            "CRP\n",
            "5.8 mg/L\n",
            "<3.0 mg/L\n",
            "\n",
            "Chunk 64:\n",
            "Synthetic Medical History - John Doe \n",
            "John Doe - Full Medical History (2020-2025) \n",
            "Extended Synthetic Medical History for John Doe (Age 27, AB+) \n",
            "Primary Profile:\n",
            "\n",
            "Chunk 65:\n",
            "Primary Profile: \n",
            "- Pre-existing Conditions: Asthma (since childhood), IBS (diagnosed 2021), Allergic Rhinitis\n",
            "\n",
            "Chunk 66:\n",
            "- Medications: Albuterol (PRN), Cetirizine, Dicyclomine (as needed), Vitamin D3 (since 2024) \n",
            "- Lifestyle: Office worker, sedentary with intermittent exercise; non-smoker; moderate alcohol use\n",
            "\n",
            "Chunk 67:\n",
            "- Family History: Mother has Type 2 Diabetes, father has hypertension \n",
            " \n",
            "MEDICAL HISTORY \n",
            "Annual Physical - Jan 2022 \n",
            "- BMI: 22.8, BP: 112/74, Labs normal\n",
            "\n",
            "Chunk 68:\n",
            "- Assessment: Healthy, encouraged more consistent exercise \n",
            " \n",
            "Pulmonary Function Test - July 2022 \n",
            "- FEV1/FVC: Mild obstruction, reversible with bronchodilator \n",
            "- Diagnosis: Controlled asthma\n",
            "\n",
            "Chunk 69:\n",
            "- Plan: Maintain current meds \n",
            " \n",
            "Psychiatry Referral - Nov 2022 \n",
            "- Note: Fatigue, stress-related GI issues, mild anxiety \n",
            "- Evaluation: Diagnosed with mild generalized anxiety\n",
            "\n",
            "Chunk 70:\n",
            "- Plan: CBT recommended, no meds\n",
            "\n",
            "Chunk 71:\n",
            "MAX Lab\n",
            "MAX Lab\n",
            "INVESTIGATION REPORT\n",
            "Name: John Doe\n",
            "Age/Gender: 27/M\n",
            "Max ID: MHIL0628744\n",
            "Ref. Doctor: SELF\n",
            "Location: Mohali\n",
            "Adm Type: OutPatient\n",
            "Order Date: 26-FEB-2025\n",
            "\n",
            "Chunk 72:\n",
            "Order Date: 26-FEB-2025\n",
            "Report Date: 26-FEB-2025 12:15 PM\n",
            "X-ray Lumbosacral (AP & Lat) of 26-FEB-2025:\n",
            "Results:\n",
            "\n",
            "Chunk 73:\n",
            "Results:\n",
            "Degenerative changes are seen in the lumbar spine in the form of marginal osteophytes and\n",
            "endplate sclerosis.\n",
            "L4-L5 and L5-S1 disc space is reduced - likely PIVD.\n",
            "\n",
            "Chunk 74:\n",
            "Rest of the vertebral bodies and appendages are normal.\n",
            "No focal lytic or sclerotic lesion seen.\n",
            "End plates and disc spaces are normal.\n",
            "Bone density is normal.\n",
            "Psoas outlines are normal.\n",
            "\n",
            "Chunk 75:\n",
            "IMPRESSION: Lumbar spondylosis with ? L4-L5 and L5-S1 PIVD\n",
            "Dr. Ambreen Jyot Sidhu\n",
            "Consultant - Radiology\n",
            "DMRD (Radiodiagnosis)\n",
            "PMC No: 43585\n",
            "Report Approved Date & Time: 26-FEB-2025 12:15 PM\n",
            "\n",
            "Chunk 76:\n",
            "Max Lab - A Division of Max Healthcare Institute Ltd\n",
            "Max Super Speciality Hospital, Mohali\n",
            "Near Civil Hospital, Phase - 6, Mohali, Punjab - 160055\n",
            "Phone: 0172 521 2000\n",
            "www.maxlab.co.in\n",
            "\n",
            "Chunk 77:\n",
            "Synthetic Medical History - John Doe \n",
            "John Doe - Full Medical History (2020-2025) \n",
            "Extended Synthetic Medical History for John Doe (Age 27, AB+) \n",
            "Primary Profile:\n",
            "\n",
            "Chunk 78:\n",
            "Primary Profile: \n",
            "- Pre-existing Conditions: Asthma (since childhood), IBS (diagnosed 2021), Allergic Rhinitis\n",
            "\n",
            "Chunk 79:\n",
            "- Medications: Albuterol (PRN), Cetirizine, Dicyclomine (as needed), Vitamin D3 (since 2024) \n",
            "- Lifestyle: Office worker, sedentary with intermittent exercise; non-smoker; moderate alcohol use\n",
            "\n",
            "Chunk 80:\n",
            "- Family History: Mother has Type 2 Diabetes, father has hypertension \n",
            "MEDICAL HISTORY \n",
            "Eye Exam - April 2023 \n",
            "- Complaint: Blurry vision after long screen time \n",
            "- Diagnosis: Digital eye strain\n",
            "\n",
            "Chunk 81:\n",
            "- Plan: Blue-light filters, 20/20/20 rule \n",
            " \n",
            "Comprehensive Metabolic Panel - Sept 2023 \n",
            "- All values normal \n",
            " \n",
            "Allergy Panel - Oct 2023 \n",
            "- Positive: Pollen, dust mites, cat dander\n",
            "\n",
            "Chunk 82:\n",
            "- Plan: Continue Cetirizine, immunotherapy discussed \n",
            "Comprehensive Metabolic Panel – Sept 2023 \n",
            "Reason: Annual screening \n",
            "Test Result Reference Range \n",
            "Glucose (fasting) 89 mg/dL 70–99 mg/dL\n",
            "\n",
            "Chunk 83:\n",
            "BUN 14 mg/dL 7–20 mg/dL \n",
            "Creatinine 0.91 mg/dL 0.6–1.3 mg/dL \n",
            "Sodium 139 mmol/L 135–145 mmol/L \n",
            "Potassium 4.3 mmol/L 3.5–5.1 mmol/L \n",
            "ALT 19 U/L 7–56 U/L \n",
            "AST 17 U/L 10–40 U/L\n",
            "\n",
            "Chunk 84:\n",
            "Synthetic Medical History - John Doe \n",
            "John Doe - Full Medical History (2020-2025) \n",
            "Extended Synthetic Medical History for John Doe (Age 27, AB+) \n",
            "Primary Profile:\n",
            "\n",
            "Chunk 85:\n",
            "Primary Profile: \n",
            "- Pre-existing Conditions: Asthma (since childhood), IBS (diagnosed 2021), Allergic Rhinitis\n",
            "\n",
            "Chunk 86:\n",
            "- Medications: Albuterol (PRN), Cetirizine, Dicyclomine (as needed), Vitamin D3 (since 2024) \n",
            "- Lifestyle: Office worker, sedentary with intermittent exercise; non-smoker; moderate alcohol use\n",
            "\n",
            "Chunk 87:\n",
            "- Family History: Mother has Type 2 Diabetes, father has hypertension \n",
            "MEDICAL HISTORY \n",
            "Consultation Note - Mar 2024 \n",
            "- Complaint: Chronic fatigue, brain fog \n",
            "- Note: Diet and sleep suboptimal\n",
            "\n",
            "Chunk 88:\n",
            "- Plan: Blood tests ordered \n",
            " \n",
            "Blood Test - Mar 2024 \n",
            "- Findings: Vitamin D: 21 ng/mL, B12: 308 pg/mL, Ferritin: 34 ng/mL \n",
            "- Plan: Start Vit D3, monitor fatigue \n",
            " \n",
            "Annual Physical - July 2024\n",
            "\n",
            "Chunk 89:\n",
            "- Vitals and urinalysis: Normal \n",
            "- Assessment: Fit for age, fatigue persists \n",
            "Blood Test – March 2024 \n",
            "Reason: Evaluation for fatigue and brain fog \n",
            "Test Result Reference Range\n",
            "\n",
            "Chunk 90:\n",
            "Vitamin D (25-OH) 21 ng/mL 30–100 ng/mL \n",
            "Vitamin B12 308 pg/mL 200–900 pg/mL \n",
            "Ferritin 34 ng/mL 30–300 ng/mL\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Embedding and Indexing"
      ],
      "metadata": {
        "id": "SVaBV7vbH8kY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.embeddings import SentenceTransformerEmbeddings\n",
        "from langchain_community.vectorstores import Chroma"
      ],
      "metadata": {
        "id": "seDRwURoIEAz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will use a sentence embedding model"
      ],
      "metadata": {
        "id": "eF0uva37IJEu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
        "print(\"Embedding model loaded.\")"
      ],
      "metadata": {
        "id": "tBxs9-tnIJue",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5130b06d-ed2e-4c09-eebd-6b9fb2995bc5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embedding model loaded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create and populate the vector store"
      ],
      "metadata": {
        "id": "4b0W9QweIwuJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "persist_directory = \"db\"  # Specify the directory for persistence\n",
        "# Create or load the Chroma vector store, enabling persistence to disk.\n",
        "vectorstore = Chroma.from_documents(\n",
        "   documents=splits, embedding=embeddings, persist_directory=persist_directory)\n",
        "vectorstore.persist()\n",
        "print(f\"Vector store created and populated with embeddings, persisted to {persist_directory}.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rgl92DUQIwKa",
        "outputId": "128a4446-a8e5-4c45-ac5a-b4caae9d1a1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vector store created and populated with embeddings, persisted to db.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Gemini LLM Setup"
      ],
      "metadata": {
        "id": "u8HXsobzJHF6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q -U google-genai  # Install or update google-genai\n",
        "!pip install -q -U google-generativeai  # Install or update google-generativeai\n",
        "\n",
        "from google.colab import userdata\n",
        "from google import genai\n",
        "\n",
        "# Set your Google API key (ensure it's stored securely)\n",
        "GOOGLE_API_KEY = userdata.get('Google_API')\n",
        "client = genai.Client(api_key=GOOGLE_API_KEY)\n",
        "MODEL = \"gemini-2.0-flash\""
      ],
      "metadata": {
        "id": "P6EUQhrvLDcE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        },
        "outputId": "8196ae9d-164b-4dc6-8e44-8d85f9f70135"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SecretNotFoundError",
          "evalue": "Secret Google_API does not exist.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mSecretNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-315c2a26ee3b>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Set your Google API key (ensure it's stored securely)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mGOOGLE_API_KEY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muserdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Google_API'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mclient\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenai\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mClient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapi_key\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mGOOGLE_API_KEY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mMODEL\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"gemini-2.0-flash\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/userdata.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(key)\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'exists'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mSecretNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'access'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mNotebookAccessError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mSecretNotFoundError\u001b[0m: Secret Google_API does not exist."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def answer_with_gemini(query):\n",
        "    \"\"\"\n",
        "    Retrieves semantically similar chunks and uses Gemini to answer the query.\n",
        "\n",
        "    Args:\n",
        "        query (str): The user's question.\n",
        "\n",
        "    Returns:\n",
        "        str: Gemini's answer to the question.\n",
        "    \"\"\"\n",
        "\n",
        "    # 1. Retrieval of semantically similar chunks:\n",
        "    retriever = vectorstore.as_retriever(search_kwargs={\"k\": 5})\n",
        "    retrieved_docs = retriever.invoke(query)\n",
        "\n",
        "    # 2. Construct the prompt for Gemini:\n",
        "    context = \"\"\n",
        "    for doc in retrieved_docs:\n",
        "        context += doc.page_content\n",
        "\n",
        "    # System instructions for summarizing and structuring\n",
        "    system_instructions = \"\"\"\n",
        "    You are a medical AI specialist trained to analyze both structured and unstructured patient health records. Based on the provided {context}, you must generate two distinct outputs:\n",
        "    Only Give the output in the specified format and don't include the questions in the output:\n",
        "    \\n'Output 1: Patient-Facing Explanation'\n",
        "    'Answer:\n",
        "    1.\n",
        "    2.\n",
        "    3. '\n",
        "\n",
        "    'Output 2: Doctor-Facing Summary'\n",
        "    'Answer:\n",
        "    1.\n",
        "    2.\n",
        "    3. '\n",
        "    \"\"\"\n",
        "\n",
        "    prompt = f\"\"\"{system_instructions}\n",
        "\n",
        "    Output 1: Patient-Facing Explanation\n",
        "\n",
        "    Use simplified, empathetic language suitable for a non-medical audience. You are a medical assistant explaining to a patient.\n",
        "\n",
        "    Prompt Format:\n",
        "\n",
        "    You are a medical assistant explaining to a patient.\n",
        "    Read the following medical record carefully and then answer the questions below in full sentences.\n",
        "\n",
        "    {context}\n",
        "\n",
        "    Questions:\n",
        "    1. What is the patient’s main health issue?\n",
        "    2. What do the test results indicate?\n",
        "    3. {user_question}?\n",
        "\n",
        "    Answer:\n",
        "\n",
        "    ⸻\n",
        "\n",
        "    Output 2: Doctor-Facing Summary\n",
        "\n",
        "    Use formal medical language appropriate for a professional healthcare provider. Provide evidence-based insights and include clinical rationale when relevant.\n",
        "\n",
        "    Prompt Format:\n",
        "\n",
        "    You are a clinical assistant. Read the following patient record:\n",
        "\n",
        "    {context}\n",
        "\n",
        "    Now answer the questions in complete sentences, referencing the record:\n",
        "    1. What is the primary diagnosis?\n",
        "    2. What are the significant lab or imaging findings?\n",
        "    3. What treatment plan is recommended, and what guidelines support it?\n",
        "\n",
        "    Answer:\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    # 3. Generate the answer using Gemini:\n",
        "    response = client.models.generate_content(\n",
        "        model=MODEL,\n",
        "        contents=prompt\n",
        "    )\n",
        "\n",
        "    return response.text"
      ],
      "metadata": {
        "id": "hhLTv7YfLIgq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Uploading A new document to the database."
      ],
      "metadata": {
        "id": "QZPreHrocOLB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sqlite3\n",
        "from google.colab import files\n",
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_community.embeddings import SentenceTransformerEmbeddings\n",
        "from langchain_community.vectorstores import Chroma\n",
        "\n",
        "\n",
        "def update_db_with_pdf(pdf_path, db_name=\"my_database.db\", persist_directory=\"db\"):\n",
        "    \"\"\"Updates the Chroma vector database with a new PDF file.\"\"\"\n",
        "\n",
        "    # 1. Upload PDF to the database (if not already present).\n",
        "    try:\n",
        "        upload_pdf_to_db(pdf_path, db_name)\n",
        "        print(f\"PDF '{pdf_path}' added to the database.\")\n",
        "    except sqlite3.IntegrityError:\n",
        "        print(f\"PDF '{pdf_path}' already exists in the database.\")\n",
        "\n",
        "\n",
        "    # 2. Load and process the new PDF.\n",
        "    loader = PyPDFLoader(pdf_path)\n",
        "    new_docs = loader.load()\n",
        "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=200, chunk_overlap=25)\n",
        "    new_splits = text_splitter.split_documents(new_docs)\n",
        "    print(f\"Loaded and split {len(new_splits)} chunks from the new PDF.\")\n",
        "\n",
        "\n",
        "    # 3. Update the Chroma vector store.\n",
        "    embeddings = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
        "    vectorstore = Chroma(persist_directory=persist_directory, embedding_function=embeddings)\n",
        "    vectorstore.add_documents(new_splits)\n",
        "    vectorstore.persist()\n",
        "    print(\"Vectorstore updated with the new PDF content.\")\n",
        "\n",
        "\n",
        "# Example usage (assuming you have a PDF file uploaded to '/content/docs'):\n",
        "\n",
        "#new_pdf_path = \"/content/docs/your_new_pdf.pdf\"  # Replace with actual path\n",
        "#update_db_with_pdf(new_pdf_path)\n",
        "\n",
        "\n",
        "# --- Helper functions from original code (slightly modified) ---\n",
        "\n",
        "def upload_pdf_to_db(pdf_path, db_name=\"my_database.db\"):\n",
        "    \"\"\"Uploads PDF content to a SQLite database.\"\"\"\n",
        "    with open(pdf_path, \"rb\") as f:\n",
        "        pdf_data = f.read()\n",
        "    conn = sqlite3.connect(db_name)\n",
        "    cursor = conn.cursor()\n",
        "    cursor.execute(\"\"\"\n",
        "        CREATE TABLE IF NOT EXISTS docs (\n",
        "            id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
        "            filename TEXT UNIQUE,  -- Enforce unique filenames\n",
        "            data BLOB\n",
        "        )\n",
        "    \"\"\")\n",
        "    try:  # Handle potential IntegrityError if the filename exists\n",
        "        cursor.execute(\"INSERT INTO docs (filename, data) VALUES (?, ?)\", (os.path.basename(pdf_path), pdf_data))\n",
        "        conn.commit()\n",
        "    except sqlite3.IntegrityError:\n",
        "        print(f\"File '{os.path.basename(pdf_path)}' already in database. Skipping.\")\n",
        "    conn.close()\n",
        "\n",
        "\n",
        "# --- Code for file upload and database update ---\n",
        "\n",
        "uploaded = files.upload()\n",
        "for filename, data in uploaded.items():\n",
        "  file_path = os.path.join(\"/content/docs\", filename)\n",
        "  with open(file_path, \"wb\") as f:\n",
        "    f.write(data)\n",
        "  update_db_with_pdf(file_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "id": "qT6NF4_lZ-T_",
        "outputId": "0f07ed2f-ac78-4e1c-a492-ebc7f499569b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-16a2b378-9f16-4b35-9fec-c014b1e92cce\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-16a2b378-9f16-4b35-9fec-c014b1e92cce\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving John_Doe_Medical_History_Integrated_removed.pdf to John_Doe_Medical_History_Integrated_removed.pdf\n",
            "PDF '/content/docs/John_Doe_Medical_History_Integrated_removed.pdf' added to the database.\n",
            "Loaded and split 34 chunks from the new PDF.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-20-6709ae233092>:31: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-chroma package and should be used instead. To use it run `pip install -U :class:`~langchain-chroma` and import as `from :class:`~langchain_chroma import Chroma``.\n",
            "  vectorstore = Chroma(persist_directory=persist_directory, embedding_function=embeddings)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vectorstore updated with the new PDF content.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Medical Assistant\n",
        "Ask questions based on newly uploaded data."
      ],
      "metadata": {
        "id": "fv66rukfgU9T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "user_question = \"Should I go visit a doctor right now?\" #@param {type:\"string\"}\n",
        "answer = answer_with_gemini(user_question)\n",
        "print(f\"Answer: {answer}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "id": "1Ggm4U__gUQo",
        "outputId": "72fb320c-d043-4297-a430-1ce23f34caea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'client' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-eed9d91414f4>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0muser_question\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Should I go visit a doctor right now?\"\u001b[0m \u001b[0;31m#@param {type:\"string\"}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0manswer_with_gemini\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_question\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Answer: {answer}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-19-afb7b8892be0>\u001b[0m in \u001b[0;36manswer_with_gemini\u001b[0;34m(query)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0;31m# 3. Generate the answer using Gemini:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m     response = client.models.generate_content(\n\u001b[0m\u001b[1;32m     81\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mMODEL\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0mcontents\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'client' is not defined"
          ]
        }
      ]
    }
  ]
}